{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fd33e28",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9fd37d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras import layers, callbacks, optimizers\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "import shap\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ef6a7d",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0773002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>p000001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>83.14</td>\n",
       "      <td>37.143754</td>\n",
       "      <td>245.289318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>p000001</td>\n",
       "      <td>6.0</td>\n",
       "      <td>83.14</td>\n",
       "      <td>37.143754</td>\n",
       "      <td>245.289318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>p000001</td>\n",
       "      <td>7.0</td>\n",
       "      <td>83.14</td>\n",
       "      <td>36.110000</td>\n",
       "      <td>245.289318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>p000001</td>\n",
       "      <td>8.0</td>\n",
       "      <td>83.14</td>\n",
       "      <td>37.143754</td>\n",
       "      <td>245.289318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>p000001</td>\n",
       "      <td>9.0</td>\n",
       "      <td>83.14</td>\n",
       "      <td>37.143754</td>\n",
       "      <td>245.289318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5345</th>\n",
       "      <td>0.0</td>\n",
       "      <td>p000134</td>\n",
       "      <td>28.0</td>\n",
       "      <td>64.60</td>\n",
       "      <td>37.143754</td>\n",
       "      <td>164.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5346</th>\n",
       "      <td>0.0</td>\n",
       "      <td>p000134</td>\n",
       "      <td>29.0</td>\n",
       "      <td>64.60</td>\n",
       "      <td>36.670000</td>\n",
       "      <td>164.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5347</th>\n",
       "      <td>0.0</td>\n",
       "      <td>p000134</td>\n",
       "      <td>30.0</td>\n",
       "      <td>64.60</td>\n",
       "      <td>37.143754</td>\n",
       "      <td>164.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5348</th>\n",
       "      <td>0.0</td>\n",
       "      <td>p000134</td>\n",
       "      <td>31.0</td>\n",
       "      <td>64.60</td>\n",
       "      <td>37.143754</td>\n",
       "      <td>164.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5349</th>\n",
       "      <td>0.0</td>\n",
       "      <td>p000134</td>\n",
       "      <td>32.0</td>\n",
       "      <td>64.60</td>\n",
       "      <td>37.143754</td>\n",
       "      <td>164.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5350 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label Sequence  Timestamp  feature_1  feature_2   feature_3\n",
       "0       0.0  p000001        5.0      83.14  37.143754  245.289318\n",
       "1       0.0  p000001        6.0      83.14  37.143754  245.289318\n",
       "2       0.0  p000001        7.0      83.14  36.110000  245.289318\n",
       "3       0.0  p000001        8.0      83.14  37.143754  245.289318\n",
       "4       0.0  p000001        9.0      83.14  37.143754  245.289318\n",
       "...     ...      ...        ...        ...        ...         ...\n",
       "5345    0.0  p000134       28.0      64.60  37.143754  164.000000\n",
       "5346    0.0  p000134       29.0      64.60  36.670000  164.000000\n",
       "5347    0.0  p000134       30.0      64.60  37.143754  164.000000\n",
       "5348    0.0  p000134       31.0      64.60  37.143754  164.000000\n",
       "5349    0.0  p000134       32.0      64.60  37.143754  164.000000\n",
       "\n",
       "[5350 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Read Train csv\n",
    "\n",
    "imputed_train = pd.read_csv('data_timeshap_train.csv', index_col=False)\n",
    "imputed_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99ec31da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>p000032</td>\n",
       "      <td>4.0</td>\n",
       "      <td>82.32</td>\n",
       "      <td>37.143754</td>\n",
       "      <td>245.289318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>p000032</td>\n",
       "      <td>5.0</td>\n",
       "      <td>82.32</td>\n",
       "      <td>36.720000</td>\n",
       "      <td>245.289318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>p000032</td>\n",
       "      <td>6.0</td>\n",
       "      <td>82.32</td>\n",
       "      <td>36.810000</td>\n",
       "      <td>245.289318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>p000032</td>\n",
       "      <td>7.0</td>\n",
       "      <td>82.32</td>\n",
       "      <td>37.143754</td>\n",
       "      <td>245.289318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>p000032</td>\n",
       "      <td>8.0</td>\n",
       "      <td>82.32</td>\n",
       "      <td>37.143754</td>\n",
       "      <td>245.289318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>0.0</td>\n",
       "      <td>p000128</td>\n",
       "      <td>20.0</td>\n",
       "      <td>73.09</td>\n",
       "      <td>37.143754</td>\n",
       "      <td>467.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>0.0</td>\n",
       "      <td>p000128</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73.09</td>\n",
       "      <td>36.670000</td>\n",
       "      <td>467.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>0.0</td>\n",
       "      <td>p000128</td>\n",
       "      <td>22.0</td>\n",
       "      <td>73.09</td>\n",
       "      <td>37.143754</td>\n",
       "      <td>467.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>0.0</td>\n",
       "      <td>p000128</td>\n",
       "      <td>23.0</td>\n",
       "      <td>73.09</td>\n",
       "      <td>37.143754</td>\n",
       "      <td>467.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>0.0</td>\n",
       "      <td>p000128</td>\n",
       "      <td>24.0</td>\n",
       "      <td>73.09</td>\n",
       "      <td>37.143754</td>\n",
       "      <td>467.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1350 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label Sequence  Timestamp  feature_1  feature_2   feature_3\n",
       "0       0.0  p000032        4.0      82.32  37.143754  245.289318\n",
       "1       0.0  p000032        5.0      82.32  36.720000  245.289318\n",
       "2       0.0  p000032        6.0      82.32  36.810000  245.289318\n",
       "3       0.0  p000032        7.0      82.32  37.143754  245.289318\n",
       "4       0.0  p000032        8.0      82.32  37.143754  245.289318\n",
       "...     ...      ...        ...        ...        ...         ...\n",
       "1345    0.0  p000128       20.0      73.09  37.143754  467.000000\n",
       "1346    0.0  p000128       21.0      73.09  36.670000  467.000000\n",
       "1347    0.0  p000128       22.0      73.09  37.143754  467.000000\n",
       "1348    0.0  p000128       23.0      73.09  37.143754  467.000000\n",
       "1349    0.0  p000128       24.0      73.09  37.143754  467.000000\n",
       "\n",
       "[1350 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Read Test csv\n",
    "\n",
    "imputed_test = pd.read_csv('data_timeshap_test.csv', index_col=False)\n",
    "imputed_test\n",
    "\n",
    "# Columns\n",
    "#imputed_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c898f782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_1', 'feature_2', 'feature_3']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Define Feature list\n",
    "\n",
    "features = imputed_train.columns[[3,4,5]].tolist()\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a30a4d",
   "metadata": {},
   "source": [
    "## Transofmation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1da5961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a lookback\n",
    "lookback = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011d2537",
   "metadata": {},
   "source": [
    "#### Transformation adapted to my use case - Shap doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fd3d2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error: Input 0 of layer \"forward_lstm\" is incompatible with the layer: expected \n",
    "# shape=(None, None, 4), found shape=(None, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8e0491f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before transformation, train: (5350, 5)\n",
      "Shape before transformation, test: (5350, 5)\n",
      "A sequence training data shape: (5301, 50, 4) (5301,)\n",
      "A sequence test data shape: (1301, 50, 4) (1301,)\n"
     ]
    }
   ],
   "source": [
    "##### DESIRED TRANSFORATION #####\n",
    "\n",
    "# Create a df without the 'Sequences' column\n",
    "dl_train = imputed_train[['Timestamp', 'feature_1', 'feature_2','feature_3','Label']].copy()\n",
    "\n",
    "# Create a df without the 'Sequences' column\n",
    "dl_test = imputed_test[['Timestamp', 'feature_1', 'feature_2','feature_3','Label']].copy()\n",
    "\n",
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "# Transform both train & test dataframes to numpy arrays because the split_sequences functions takes a numpy array as an input\n",
    "X_train_reshaped = dl_train.to_numpy()\n",
    "X_test_reshaped = dl_test.to_numpy()\n",
    "\n",
    "print('Shape before transformation, train:', X_train_reshaped.shape)\n",
    "print('Shape before transformation, test:', X_train_reshaped.shape)\n",
    "\n",
    "# Create the LSTM input sequence in the shape (n_rows, lookback, n_features) from the dataframes\n",
    "X_train_seq, Y_train_seq = split_sequences(X_train_reshaped, lookback)\n",
    "X_test_seq, Y_test_seq = split_sequences(X_test_reshaped, lookback)\n",
    "\n",
    "# Check the input sequence shape for the train & test datasets\n",
    "print('A sequence training data shape:', X_train_seq.shape, Y_train_seq.shape)\n",
    "print('A sequence test data shape:', X_test_seq.shape, Y_test_seq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf7bbd2",
   "metadata": {},
   "source": [
    "#### Transformation Function taken from the AReM Tutorial - Shap works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "033815c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ##### USING THE FUNCTION FROM THE TUTORIAL #####\n",
    "\n",
    "# # All features are taken \n",
    "# dl_train = imputed_train\n",
    "\n",
    "# # All features are taken \n",
    "# dl_test = imputed_test\n",
    "\n",
    "\n",
    "# def df_to_numpy(df, model_feats, label_feat, group_by_feat, timestamp_Feat):\n",
    "    \n",
    "#     sequence_length = 50\n",
    "\n",
    "#     data_tensor = np.zeros(\n",
    "#     (len(df[group_by_feat].unique()), sequence_length, len(model_feats)))\n",
    "    \n",
    "#     labels_tensor = np.zeros((len(df[group_by_feat].unique()), ))\n",
    "\n",
    "#     for i, name in enumerate(df[group_by_feat].unique()):\n",
    "\n",
    "#         name_data = df[df[group_by_feat] == name]\n",
    "#         sorted_data = name_data.sort_values(timestamp_Feat)\n",
    "        \n",
    "#         data_x = sorted_data[model_feats].values\n",
    "#         labels = sorted_data[label_feat].values\n",
    "\n",
    "#         data_tensor[i, :, :] = data_x\n",
    "#         labels_tensor[i, ] = np.max(labels)\n",
    "    \n",
    "#     return data_tensor, labels_tensor\n",
    "\n",
    "\n",
    "# X_train_seq, Y_train_seq = df_to_numpy(dl_train, features, 'Label', 'Sequence', 'Timestamp')\n",
    "# X_test_seq, Y_test_seq = df_to_numpy(dl_test, features, 'Label', 'Sequence', 'Timestamp')\n",
    "\n",
    "# print('Shape before transformation, train:', dl_train.shape)\n",
    "# print('Shape before transformation, test:', dl_test.shape)\n",
    "\n",
    "# # Check the input sequence shape for the train & test datasets\n",
    "# print('A sequence training data shape:', X_train_seq.shape, Y_train_seq.shape)\n",
    "# print('A sequence test data shape:', X_test_seq.shape, Y_test_seq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86465b7f",
   "metadata": {},
   "source": [
    "## Define LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "320abce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with batch_size & lookback = 50\n"
     ]
    }
   ],
   "source": [
    "# Set the random seed into the tensorflow backend to re-create results\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Set the number of features to be used as an input\n",
    "n_features = len(features)\n",
    "batch_size = lookback\n",
    "print('Training with batch_size & lookback =', str(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fb3519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the previous sessions in the tensorflow backend are cleared\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# Layer 1\n",
    "model.add(Bidirectional(LSTM(26, activation='tanh', return_sequences=True, input_shape=(lookback, n_features))))\n",
    "\n",
    "# Layer 2 \n",
    "model.add(Bidirectional(LSTM(12, activation='tanh')))\n",
    "\n",
    "# Layer 3 - Prediction layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "##Compile the LSTM model & define the optimization function\n",
    "\n",
    "# Define the model optimization function to the Adam optimizer and set the learning rate\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Define the early stopping function to stop the model before it starts overfitting\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, min_delta=0.001, restore_best_weights=True)\n",
    "\n",
    "# Compile the model using the \"binary_crossentropy\" loss function\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy', keras.metrics.Precision(), keras.metrics.Recall()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12584a28",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64fede42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "107/107 [==============================] - 15s 54ms/step - loss: 0.1046 - binary_accuracy: 0.9787 - precision: 1.0000 - recall: 0.0174 - val_loss: 0.0997 - val_binary_accuracy: 0.9846 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/400\n",
      "107/107 [==============================] - 4s 40ms/step - loss: 0.1065 - binary_accuracy: 0.9783 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0868 - val_binary_accuracy: 0.9846 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/400\n",
      "107/107 [==============================] - 4s 36ms/step - loss: 0.1015 - binary_accuracy: 0.9783 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0847 - val_binary_accuracy: 0.9846 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/400\n",
      "107/107 [==============================] - 4s 38ms/step - loss: 0.1018 - binary_accuracy: 0.9783 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0778 - val_binary_accuracy: 0.9846 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/400\n",
      "107/107 [==============================] - 5s 49ms/step - loss: 0.0996 - binary_accuracy: 0.9783 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0776 - val_binary_accuracy: 0.9846 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/400\n",
      "107/107 [==============================] - 4s 39ms/step - loss: 0.0998 - binary_accuracy: 0.9783 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0790 - val_binary_accuracy: 0.9846 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/400\n",
      "107/107 [==============================] - 4s 39ms/step - loss: 0.0995 - binary_accuracy: 0.9783 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0763 - val_binary_accuracy: 0.9846 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/400\n",
      "107/107 [==============================] - 4s 39ms/step - loss: 0.0996 - binary_accuracy: 0.9783 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0757 - val_binary_accuracy: 0.9846 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/400\n",
      "107/107 [==============================] - 4s 42ms/step - loss: 0.0988 - binary_accuracy: 0.9783 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0751 - val_binary_accuracy: 0.9846 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/400\n",
      "107/107 [==============================] - 4s 37ms/step - loss: 0.0997 - binary_accuracy: 0.9783 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0770 - val_binary_accuracy: 0.9846 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/400\n",
      "107/107 [==============================] - 4s 36ms/step - loss: 0.0989 - binary_accuracy: 0.9783 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0747 - val_binary_accuracy: 0.9846 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/400\n",
      "107/107 [==============================] - 4s 33ms/step - loss: 0.0980 - binary_accuracy: 0.9783 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0744 - val_binary_accuracy: 0.9846 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/400\n",
      "107/107 [==============================] - 4s 34ms/step - loss: 0.0982 - binary_accuracy: 0.9783 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0742 - val_binary_accuracy: 0.9846 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/400\n",
      "107/107 [==============================] - 4s 38ms/step - loss: 0.0981 - binary_accuracy: 0.9783 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0741 - val_binary_accuracy: 0.9846 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/400\n",
      "107/107 [==============================] - 4s 35ms/step - loss: 0.0965 - binary_accuracy: 0.9783 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0910 - val_binary_accuracy: 0.9846 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/400\n",
      "107/107 [==============================] - 4s 33ms/step - loss: 0.1009 - binary_accuracy: 0.9783 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0834 - val_binary_accuracy: 0.9846 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/400\n",
      "107/107 [==============================] - 4s 33ms/step - loss: 0.1019 - binary_accuracy: 0.9783 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0838 - val_binary_accuracy: 0.9846 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/400\n",
      "107/107 [==============================] - 4s 34ms/step - loss: 0.1013 - binary_accuracy: 0.9783 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0807 - val_binary_accuracy: 0.9846 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/400\n",
      "107/107 [==============================] - 4s 37ms/step - loss: 0.0982 - binary_accuracy: 0.9783 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0795 - val_binary_accuracy: 0.9846 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/400\n",
      "107/107 [==============================] - 4s 33ms/step - loss: 0.0991 - binary_accuracy: 0.9783 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0795 - val_binary_accuracy: 0.9846 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/400\n",
      "107/107 [==============================] - 4s 34ms/step - loss: 0.0925 - binary_accuracy: 0.9783 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0790 - val_binary_accuracy: 0.9846 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/400\n",
      "107/107 [==============================] - 4s 34ms/step - loss: 0.0941 - binary_accuracy: 0.9783 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0858 - val_binary_accuracy: 0.9846 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/400\n",
      "107/107 [==============================] - 4s 33ms/step - loss: 0.0843 - binary_accuracy: 0.9783 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0731 - val_binary_accuracy: 0.9846 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/400\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0841 - binary_accuracy: 0.9783 - precision: 0.0000e+00 - recall: 0.0000e+00Restoring model weights from the end of the best epoch: 14.\n",
      "107/107 [==============================] - 4s 33ms/step - loss: 0.0841 - binary_accuracy: 0.9783 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0845 - val_binary_accuracy: 0.9846 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_seq, Y_train_seq,\n",
    "    validation_data=(X_test_seq, Y_test_seq),\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    "    epochs=400,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15ad5e0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "# history_df = pd.DataFrame(history.history)\n",
    "# print(('Best Validation Loss: {}'.format(round(history_df['val_loss'].min(),2))))\n",
    "# print(('Best Validation Accuracy: {}'.format(round(history_df['val_binary_accuracy'].max(),2))))\n",
    "# print(('Best Validation Precision: {}'.format(round(history_df['val_precision'].max(),2))))\n",
    "# print(('Best Validation Recall: {}'.format(round(history_df['val_recall'].max(),2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c9977b",
   "metadata": {},
   "source": [
    "## SHAP Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b45c42",
   "metadata": {},
   "source": [
    "###### Define Naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f5095b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define variables' the naming\n",
    "\n",
    "model_features = features \n",
    "label = 'Label'\n",
    "sequence_id_feat = 'Sequence' \n",
    "time_feat = 'Timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21ec441b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_1', 'feature_2', 'feature_3']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3181a6b",
   "metadata": {},
   "source": [
    "###### What Sequence to be explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7dcc6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>27.92</td>\n",
       "      <td>37.940000</td>\n",
       "      <td>448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>27.92</td>\n",
       "      <td>37.143754</td>\n",
       "      <td>448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>27.92</td>\n",
       "      <td>37.143754</td>\n",
       "      <td>448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>27.92</td>\n",
       "      <td>38.780000</td>\n",
       "      <td>448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>27.92</td>\n",
       "      <td>37.143754</td>\n",
       "      <td>448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>27.92</td>\n",
       "      <td>37.143754</td>\n",
       "      <td>448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>27.92</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>27.92</td>\n",
       "      <td>37.143754</td>\n",
       "      <td>448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>27.92</td>\n",
       "      <td>37.143754</td>\n",
       "      <td>448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>27.92</td>\n",
       "      <td>38.330000</td>\n",
       "      <td>448.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_1  feature_2  feature_3\n",
       "50      27.92  37.940000      448.0\n",
       "51      27.92  37.143754      448.0\n",
       "52      27.92  37.143754      448.0\n",
       "53      27.92  38.780000      448.0\n",
       "54      27.92  37.143754      448.0\n",
       "55      27.92  37.143754      448.0\n",
       "56      27.92  39.000000      448.0\n",
       "57      27.92  37.143754      448.0\n",
       "58      27.92  37.143754      448.0\n",
       "59      27.92  38.330000      448.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## For our local explanations, we will be explaining the sequence defined as 'what_to_explain'\n",
    "\n",
    "what_to_explain = 'p000009'\n",
    "positive_sequence_id = what_to_explain\n",
    "\n",
    "pos_x_data = imputed_train[imputed_train['Sequence']==what_to_explain]\n",
    "pos_x_data = pos_x_data[model_features]\n",
    "\n",
    "pos_x_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324f6324",
   "metadata": {},
   "source": [
    "##### Model entry point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea86c773",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c314e27b",
   "metadata": {},
   "source": [
    "###### Baseline event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "458d55fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeshap.utils import calc_avg_event\n",
    "average_event = calc_avg_event(dl_train, numerical_feats=model_features, categorical_feats=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23bec052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51.14</td>\n",
       "      <td>37.143754</td>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3\n",
       "0      51.14  37.143754      158.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_event"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b937a81",
   "metadata": {},
   "source": [
    "###### Average score over baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee9e2b3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\marcin.grzechowiak\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\marcin.grzechowiak\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\marcin.grzechowiak\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\marcin.grzechowiak\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\marcin.grzechowiak\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\marcin.grzechowiak\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Exception encountered when calling layer \"bidirectional\" (type Bidirectional).\n    \n    Input 0 of layer \"forward_lstm\" is incompatible with the layer: expected shape=(None, None, 4), found shape=(None, 1, 3)\n    \n    Call arguments received:\n      â€¢ inputs=tf.Tensor(shape=(None, 1, 3), dtype=float32)\n      â€¢ training=False\n      â€¢ mask=None\n      â€¢ initial_state=None\n      â€¢ constants=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MARCIN~1.GRZ\\AppData\\Local\\Temp/ipykernel_19992/900875417.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtimeshap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_avg_score_with_avg_event\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mavg_score_over_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_avg_score_with_avg_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage_event\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\timeshap\\utils\\utils.py\u001b[0m in \u001b[0;36mget_avg_score_with_avg_event\u001b[1;34m(model, med, top)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mexpanded_copy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpanded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__code__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mco_varnames\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpanded_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpanded_copy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MARCIN~1.GRZ\\AppData\\Local\\Temp/ipykernel_19992/667494770.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\marcin.grzechowiak\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\marcin.grzechowiak\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\marcin.grzechowiak\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\marcin.grzechowiak\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\marcin.grzechowiak\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\marcin.grzechowiak\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Exception encountered when calling layer \"bidirectional\" (type Bidirectional).\n    \n    Input 0 of layer \"forward_lstm\" is incompatible with the layer: expected shape=(None, None, 4), found shape=(None, 1, 3)\n    \n    Call arguments received:\n      â€¢ inputs=tf.Tensor(shape=(None, 1, 3), dtype=float32)\n      â€¢ training=False\n      â€¢ mask=None\n      â€¢ initial_state=None\n      â€¢ constants=None\n"
     ]
    }
   ],
   "source": [
    "from timeshap.utils import get_avg_score_with_avg_event\n",
    "avg_score_over_len = get_avg_score_with_avg_event(f, average_event, top=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ffc332",
   "metadata": {},
   "source": [
    "### Local Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fed2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeshap.plot import plot_temp_coalition_pruning, plot_event_heatmap, plot_feat_barplot, plot_cell_level\n",
    "from timeshap.explainer import local_pruning, local_event, local_feat, local_cell_level\n",
    "\n",
    "# convert the instance to numpy so TimeSHAP receives it\n",
    "pos_x_data = np.expand_dims(pos_x_data.to_numpy().copy(), axis=0)\n",
    "pos_x_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5882f3a3",
   "metadata": {},
   "source": [
    "###### Pruning Alrogithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f242b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_dict = {'tol': 0.025}\n",
    "coal_plot_data, coal_prun_idx = local_pruning(f, pos_x_data, pruning_dict, average_event, positive_sequence_id, False)\n",
    "# coal_prun_idx is in negative terms\n",
    "pruning_idx = pos_x_data.shape[1] + coal_prun_idx\n",
    "pruning_plot = plot_temp_coalition_pruning(coal_plot_data, coal_prun_idx) #, plot_limit=40)\n",
    "pruning_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc3974a",
   "metadata": {},
   "source": [
    "##### Event-level explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c43a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dict = {'rs': 42, 'nsamples': 32000}\n",
    "event_data = local_event(f, pos_x_data, event_dict, positive_sequence_id, sequence_id_feat, average_event, pruning_idx)\n",
    "event_plot = plot_event_heatmap(event_data)\n",
    "event_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3052c885",
   "metadata": {},
   "source": [
    "##### Feature-level explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a65cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict = {'rs': 42, 'nsamples': 32000, 'feature_names': model_features}\n",
    "feature_data = local_feat(f, pos_x_data, feature_dict, positive_sequence_id, sequence_id_feat, average_event, pruning_idx)\n",
    "feature_plot = plot_feat_barplot(feature_data, feature_dict.get('top_feats'), feature_dict.get('plot_features'))\n",
    "feature_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32805403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-level explanation - Table view\n",
    "feature_data.sort_values('Shapley Value')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
